# -*- coding: utf-8 -*-
"""LoanPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xxTJ9X74fmQzrsNbGCzViPuPbR1Y57Xj
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data_info= pd.read_csv('lending_club_info.csv',index_col='LoanStatNew')

data_info.info()

data_info['Description']

df= pd.read_csv('lending_club_loan_two.csv')

df.info()

df.head()

df.describe().transpose()

df.isnull().sum()

df=df.dropna(axis=1)

df['loan_status'].value_counts()

sns.countplot(df['loan_status'])

sns.countplot(x='loan_status',hue='grade',data=df)

df['loan_status']= df['loan_status'].apply(lambda x: int(x==('Fully Paid')))

tb_sum=(df.groupby('sub_grade')['loan_status']).sum()
# tb_sum= tb_sum.astype('float64')
tb_cnt=(df.groupby('sub_grade')['loan_status']).count()
# tb_cnt= tb_cnt.astype('float64')
df['grade_']= df['sub_grade'].apply(lambda x: (tb_sum[x]/tb_cnt[x]))
# (tb_sum['A1']*1.0)/tb_cnt['A1']

df['application_type'].value_counts()

sns.countplot(x='loan_status',hue='application_type',data=df)

df.corr()['loan_status']

sns.distplot(df['loan_amnt'])

sns.boxplot(x='loan_status',y='int_rate',data=df)

# df['int_rate']= df['int_rate']**(1.5)

df['term']= pd.get_dummies(df['term'],drop_first=True)

df['term'].value_counts()

df.corr()['loan_status']

df['home_ownership'].unique()

home= pd.get_dummies(df['home_ownership'])

df=pd.concat([df,home[['RENT', 'MORTGAGE', 'OWN']]],axis=1)

df['verification_status']= df['verification_status'].apply(lambda x: int(x=='Not Verified'))

df.corr()['loan_status']

df['initial_list_status']= pd.get_dummies(df['initial_list_status'],drop_first=True)

plt.figure(figsize=(14,14))
sns.heatmap(df.corr(),annot=True)

df.isnull().sum()

from sklearn.model_selection import train_test_split

X=df[['loan_amnt', 'term', 'int_rate', 'installment', 'annual_inc',
       'verification_status', 'dti', 'open_acc', 'pub_rec',
       'revol_bal', 'total_acc', 'initial_list_status', 'grade_', 'RENT',
       'MORTGAGE', 'OWN']]
y=df['loan_status']

X.isnull().sum()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# from sklearn.utils import resample
# train= pd.concat([X_train,y_train],axis=1)
# negetive= train[train['loan_status']==0]
# positive= train[train['loan_status']==1]

# resam= resample(positive,replace=True, n_samples=int(len(positive)*0.8),random_state=42)
# train= pd.concat([positive,negetive],axis=0)
# train

# X_train= train.drop('loan_status',axis=1).values
# y_train= train['loan_status'].values

from sklearn.preprocessing import MinMaxScaler

scaler= MinMaxScaler()

X_train= scaler.fit_transform(X_train)
X_test= scaler.transform(X_test)

type(y_test)

X_train.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping

model= Sequential()
# model.add(Input(shape=(3,)))
model.add(Dense(16,activation='tanh'))
model.add(Dropout(0.25))
model.add(Dense(8,activation='tanh'))
model.add(Dropout(0.25))

model.add(Dense(1, activation="sigmoid"))

model.compile(loss='binary_crossentropy', optimizer='adam')

early_stop= EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=10)

model.fit(X_train,y_train,epochs=40,batch_size=256,validation_data=(X_test,y_test))

pred= model.predict(X_test)
predictions=[]
for x in pred:
  if x>=0.6:
    predictions.append(1)
  else:
    predictions.append(0)
predictions= np.array(predictions)

predictions.sum()

predictions.shape

from sklearn.metrics import confusion_matrix, classification_report

print(confusion_matrix(y_test,predictions))

print(classification_report(y_test,predictions))

from sklearn.metrics import f1_score

print(f1_score(y_test,predictions))

model.save('model.h5')

